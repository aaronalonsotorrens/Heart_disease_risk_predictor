{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8df5593",
   "metadata": {},
   "source": [
    "## Notebook 7: Model Deployment & Inference (Heart Disease Dataset)\n",
    "\n",
    "In this notebook, we deploy the best-performing pipeline from Notebook 6 for inference on new patient data, including interpretability enhancements.\n",
    "\n",
    "## **Goals**\n",
    "\n",
    "- Load the final best model pipeline  \n",
    "\n",
    "- Provide helper functions for consistent preprocessing and inference  \n",
    "\n",
    "- Generate enriched predictions with risk bands and recommendations  \n",
    "\n",
    "- Identify top feature contributions for interpretability  \n",
    "\n",
    "- Validate inference on sample patients and full feature sets  \n",
    "\n",
    "- Save the deployment-ready pipeline  \n",
    "\n",
    "## **Workflow**\n",
    "\n",
    "1. Load the final best model pipeline from Notebook 6  \n",
    "\n",
    "2. Implement helper functions for input alignment and prediction  \n",
    "\n",
    "3. Extend predictions with risk bands, recommendations, and feature contributions  \n",
    "\n",
    "4. Test enhanced inference on sample patient records (simplified & full feature sets)  \n",
    "\n",
    "5. Save the deployment-ready pipeline as a backup  \n",
    "\n",
    "By the end of this notebook, we will have a fully functional inference workflow providing predictions, risk stratification, and interpretability outputs ready for integration into an application or API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c0b716",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7.1 Load Best Model Pipeline\n",
    "\n",
    "Purpose  \n",
    "\n",
    "Load the final best model pipeline saved in Notebook 6 for deployment and inference.\n",
    "\n",
    "Approach  \n",
    "\n",
    "- Import `joblib`.  \n",
    "\n",
    "- Load the pipeline from the deployment directory.\n",
    "\n",
    "Expected Outcome  \n",
    "\n",
    "Pipeline `pipeline_best` is ready for inference on new patient data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762cebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded best model pipeline from /workspaces/Heart_disease_risk_predictor/outputs/models/deployment/best_model_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "best_model_path = (\n",
    "    \"/workspaces/Heart_disease_risk_predictor/outputs/models/deployment/\"\n",
    "    \"best_model_pipeline.pkl\"\n",
    ")\n",
    "pipeline_best = joblib.load(best_model_path)\n",
    "print(f\"✅ Loaded best model pipeline from {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2c6ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7.2 Helper Functions for Inference\n",
    "\n",
    "Purpose  \n",
    "\n",
    "Provide utility functions to standardize inference on new input data.\n",
    "\n",
    "Approach  \n",
    "\n",
    "- `get_expected_features()` → get feature names from pipeline.  \n",
    "\n",
    "- `align_input()` → align new input DataFrame with training schema.  \n",
    "\n",
    "- `predict_pipeline()` → run inference and return class + probability.  \n",
    "\n",
    "- `predict_from_dict()` → convenience wrapper for dict input.\n",
    "\n",
    "Expected Outcome  \n",
    "\n",
    "Reusable helper functions for consistent preprocessing and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8fa532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_features(model_pipeline):\n",
    "    \"\"\"\n",
    "    Extract original feature names from the pipeline.\n",
    "    \"\"\"\n",
    "    if \"preprocessor\" in model_pipeline.named_steps:\n",
    "        preprocessor = model_pipeline.named_steps[\"preprocessor\"]\n",
    "        if hasattr(preprocessor, \"feature_names_in_\"):\n",
    "            return list(preprocessor.feature_names_in_)\n",
    "    return None\n",
    "\n",
    "\n",
    "def align_input(sample_data: pd.DataFrame, expected_features):\n",
    "    \"\"\"\n",
    "    Align new input to match training schema.\n",
    "    Missing cols -> filled with 0\n",
    "    Extra cols -> dropped\n",
    "    \"\"\"\n",
    "    return sample_data.reindex(columns=expected_features, fill_value=0)\n",
    "\n",
    "\n",
    "def predict_pipeline(model_pipeline, new_data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Run inference using a preprocessing + model pipeline.\n",
    "    Returns predicted class and probability.\n",
    "    \"\"\"\n",
    "    pred_class = model_pipeline.predict(new_data)\n",
    "    pred_proba = model_pipeline.predict_proba(new_data)[:, 1]\n",
    "    return pred_class, pred_proba\n",
    "\n",
    "\n",
    "def predict_from_dict(model_pipeline, patient_dict: dict):\n",
    "    \"\"\"\n",
    "    Convenience wrapper: pass patient record as dict.\n",
    "    Auto-aligns to training schema.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([patient_dict])\n",
    "    expected_features = get_expected_features(model_pipeline)\n",
    "    if expected_features is not None:\n",
    "        df = align_input(df, expected_features)\n",
    "    return predict_pipeline(model_pipeline, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c528cde",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7.3 Enhanced Inference with Risk Bands & Feature Contributions\n",
    "\n",
    "Purpose  \n",
    "\n",
    "Provide enriched predictions with:  \n",
    "\n",
    "- Risk band classification (Low / Medium / High)  \n",
    "\n",
    "- Recommendations  \n",
    "\n",
    "- Top contributing features\n",
    "\n",
    "Approach  \n",
    "\n",
    "- Align features to training schema.  \n",
    "\n",
    "- Predict class and probability.  \n",
    "\n",
    "- Map probability to risk band.  \n",
    "\n",
    "- Generate recommendation based on risk.  \n",
    "\n",
    "- Calculate feature contributions:  \n",
    "\n",
    "  - Logistic Regression → scaled input × coefficients  \n",
    "\n",
    "  - Tree-based models → approximate via feature importances\n",
    "\n",
    "Expected Outcome  \n",
    "\n",
    "Enhanced prediction outputs including probability, risk band, recommendation, and top feature contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27443a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_band(prob):\n",
    "    \"\"\"Translate probability into Low / Medium / High risk.\"\"\"\n",
    "    if prob < 0.2:\n",
    "        return \"Low\"\n",
    "    elif prob < 0.5:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "\n",
    "def enhanced_predict(model_pipeline, new_data: pd.DataFrame, top_n=3):\n",
    "    \"\"\"\n",
    "    Enhanced prediction: class, probability, risk band,\n",
    "    top contributing features, and recommendation.\n",
    "    \"\"\"\n",
    "    # Align features\n",
    "    expected_features = get_expected_features(model_pipeline)\n",
    "    if expected_features is not None:\n",
    "        new_data = align_input(new_data, expected_features)\n",
    "\n",
    "    # Predict class and probability\n",
    "    pred_class = int(model_pipeline.predict(new_data)[0])\n",
    "    pred_proba = float(model_pipeline.predict_proba(new_data)[:, 1][0])\n",
    "    pred_proba_pct = round(\n",
    "        pred_proba * 100, 1\n",
    "    )  # convert to percentage with 1 decimal\n",
    "    band = risk_band(pred_proba)\n",
    "\n",
    "    # Recommendation\n",
    "    recommendation = (\n",
    "        \"Maintain healthy lifestyle\"\n",
    "        if band == \"Low\"\n",
    "        else \"Recommend further testing\"\n",
    "    )\n",
    "\n",
    "    # Feature contributions\n",
    "    preprocessor = model_pipeline.named_steps.get(\"preprocessor\")\n",
    "    feature_names = (\n",
    "        preprocessor.get_feature_names_out()\n",
    "        if hasattr(preprocessor, \"get_feature_names_out\")\n",
    "        else [f\"f{i}\" for i in range(new_data.shape[1])]\n",
    "    )\n",
    "\n",
    "    contributions = None\n",
    "    # Logistic Regression → scaled input × coefficients\n",
    "    if \"log_reg\" in model_pipeline.named_steps:\n",
    "        model = model_pipeline.named_steps[\"log_reg\"]\n",
    "        X_scaled = preprocessor.transform(new_data)\n",
    "        contributions = (\n",
    "            X_scaled.toarray() if hasattr(X_scaled, \"toarray\") else X_scaled\n",
    "        )[0] * model.coef_[0]\n",
    "\n",
    "    # Tree-based models → approximate with feature importances\n",
    "    elif any(k in model_pipeline.named_steps for k in [\"rf\", \"xgb\", \"lgbm\"]):\n",
    "        model = list(model_pipeline.named_steps.values())[-1]\n",
    "        importances = model.feature_importances_\n",
    "        contributions = importances * pred_proba  # rough approximation\n",
    "\n",
    "    # Build top contributions dataframe\n",
    "    if contributions is not None and len(contributions) == len(feature_names):\n",
    "        contrib_df = pd.DataFrame(\n",
    "            {\"Feature\": feature_names, \"Contribution\": contributions}\n",
    "        ).reindex(feature_names)\n",
    "        contrib_df = contrib_df.reindex(\n",
    "            contrib_df.Contribution.abs().sort_values(ascending=False).index\n",
    "        )\n",
    "        top_contrib = contrib_df.head(top_n)\n",
    "    else:\n",
    "        top_contrib = pd.DataFrame(columns=[\"Feature\", \"Contribution\"])\n",
    "\n",
    "    return {\n",
    "        \"Prediction\": pred_class,\n",
    "        \"Probability\": pred_proba_pct,  # now in %\n",
    "        \"Risk Band\": band,\n",
    "        \"Recommendation\": recommendation,\n",
    "        \"Top Contributions\": top_contrib,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b5463",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7.4 Test Enhanced Inference with Sample Patient\n",
    "\n",
    "Purpose  \n",
    "\n",
    "Validate the enhanced inference function on example patient records.\n",
    "\n",
    "Approach  \n",
    "\n",
    "- Create sample patient dictionaries.  \n",
    "\n",
    "- Convert to DataFrame.  \n",
    "\n",
    "- Call `enhanced_predict()` and print results.\n",
    "\n",
    "Expected Outcome  \n",
    "\n",
    "Predicted class, probability, risk band, recommendation, and top contributing features for sample patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fcad2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Best Model Enhanced Prediction\n",
      "Prediction: 0\n",
      "Probability: 44.7\n",
      "Risk Band: Medium\n",
      "Recommendation: Recommend further testing\n",
      "🔹 High-Risk Patient Prediction\n",
      "Prediction: 1\n",
      "Probability: 51.4 %\n",
      "Risk Band: High\n",
      "Recommendation: Recommend further testing\n",
      "Top Contributions:\n",
      "               Feature  Contribution\n",
      "num__id           NaN           NaN\n",
      "num__age          NaN           NaN\n",
      "num__trestbps     NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "# Example patient\n",
    "sample_patient = {\n",
    "    \"age\": 55,\n",
    "    \"sex\": 1,\n",
    "    \"cp\": 3,\n",
    "    \"trestbps\": 240,\n",
    "    \"chol\": 220,\n",
    "    \"fbs\": 0,\n",
    "    \"restecg\": 1,\n",
    "    \"thalch\": 150,\n",
    "    \"exang\": 0,\n",
    "    \"oldpeak\": 1.5,\n",
    "}\n",
    "\n",
    "sample_df = pd.DataFrame([sample_patient])\n",
    "result = enhanced_predict(pipeline_best, sample_df)\n",
    "\n",
    "print(\"🔹 Best Model Enhanced Prediction\")\n",
    "print(\"Prediction:\", result[\"Prediction\"])\n",
    "print(\"Probability:\", result[\"Probability\"])\n",
    "print(\"Risk Band:\", result[\"Risk Band\"])\n",
    "print(\"Recommendation:\", result[\"Recommendation\"])\n",
    "\n",
    "\n",
    "high_risk_patient = {\n",
    "    \"age\": 68,\n",
    "    \"sex\": 1,  # male\n",
    "    \"cp\": 4,  # typical angina\n",
    "    \"trestbps\": 180,  # high resting blood pressure\n",
    "    \"chol\": 300,  # high cholesterol\n",
    "    \"fbs\": 1,  # fasting blood sugar > 120 mg/dl\n",
    "    \"restecg\": 2,  # abnormal ECG\n",
    "    \"thalch\": 120,  # low max heart rate achieved\n",
    "    \"exang\": 1,  # exercise-induced angina\n",
    "    \"oldpeak\": 3.0,  # ST depression\n",
    "}\n",
    "\n",
    "high_risk_df = pd.DataFrame([high_risk_patient])\n",
    "result_high = enhanced_predict(pipeline_best, high_risk_df)\n",
    "\n",
    "print(\"🔹 High-Risk Patient Prediction\")\n",
    "print(\"Prediction:\", result_high[\"Prediction\"])\n",
    "print(\"Probability:\", result_high[\"Probability\"], \"%\")\n",
    "print(\"Risk Band:\", result_high[\"Risk Band\"])\n",
    "print(\"Recommendation:\", result_high[\"Recommendation\"])\n",
    "print(\"Top Contributions:\\n\", result_high[\"Top Contributions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37593afd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7.5 Test with Full Feature Set (22 features)\n",
    "\n",
    "**Purpose**  \n",
    "\n",
    "Validate whether providing *all engineered and categorical features* (as used during training) results in more confident predictions compared to using only the simplified clinical input set.  \n",
    "\n",
    "**Approach**  \n",
    "\n",
    "- Construct a synthetic patient record with all 22 features filled.  \n",
    "\n",
    "- Run inference through the enhanced prediction pipeline.  \n",
    "\n",
    "- Compare probability outputs to those obtained from the reduced feature set.  \n",
    "\n",
    "**Expected Outcome**  \n",
    "\n",
    "Predictions should show higher probability separation (e.g., ~70–80% for high-risk patients), demonstrating that the model benefits from the full feature space.  \n",
    "\n",
    "**Summary of Results**  \n",
    "\n",
    "Using the full 22-feature set, the high-risk test patient achieved **76.6% probability**, compared to ~50% with the simplified set. This confirms that richer inputs sharpen the model’s confidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5218fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Full-Feature Patient Prediction\n",
      "Prediction: 1\n",
      "Probability: 76.6 %\n",
      "Risk Band: High\n",
      "Recommendation: Recommend further testing\n",
      "Top Contributions:\n",
      "               Feature  Contribution\n",
      "num__id           NaN           NaN\n",
      "num__age          NaN           NaN\n",
      "num__trestbps     NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "full_patient = {\n",
    "    \"id\": 999,\n",
    "    \"age\": 70,\n",
    "    \"trestbps\": 180,\n",
    "    \"chol\": 300,\n",
    "    \"thalch\": 100,\n",
    "    \"oldpeak\": 4.0,\n",
    "    \"sex_Male\": 1,\n",
    "    \"dataset_Hungary\": 0,\n",
    "    \"dataset_Switzerland\": 0,\n",
    "    \"dataset_VA Long Beach\": 0,\n",
    "    \"cp_atypical angina\": 0,\n",
    "    \"cp_non-anginal\": 0,\n",
    "    \"cp_typical angina\": 1,\n",
    "    \"fbs_True\": 1,\n",
    "    \"restecg_normal\": 0,\n",
    "    \"restecg_st-t abnormality\": 1,\n",
    "    \"exang_True\": 1,\n",
    "    # engineered features\n",
    "    \"chol_age_ratio\": 300 / 70,\n",
    "    \"oldpeak_thalach_ratio\": 4.0 / 100,\n",
    "    \"age_trestbps\": 70 * 180,\n",
    "    \"thalch_oldpeak\": 100 * 4.0,\n",
    "    \"age_group\": 4,  # e.g. bin label for age 70\n",
    "}\n",
    "\n",
    "full_patient_df = pd.DataFrame([full_patient])\n",
    "result_full = enhanced_predict(pipeline_best, full_patient_df)\n",
    "\n",
    "print(\"🔹 Full-Feature Patient Prediction\")\n",
    "print(\"Prediction:\", result_full[\"Prediction\"])\n",
    "print(\"Probability:\", result_full[\"Probability\"], \"%\")\n",
    "print(\"Risk Band:\", result_full[\"Risk Band\"])\n",
    "print(\"Recommendation:\", result_full[\"Recommendation\"])\n",
    "print(\"Top Contributions:\\n\", result_full[\"Top Contributions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e8ced",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7.6 Save Deployment Pipeline (optional backup)\n",
    "\n",
    "Purpose  \n",
    "\n",
    "Ensure the deployment-ready pipeline is saved for production use.\n",
    "\n",
    "Approach  \n",
    "\n",
    "- Save `pipeline_best` using `joblib`.  \n",
    "\n",
    "Expected Outcome  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fdbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model pipeline saved for deployment.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\n",
    "    \"/workspaces/Heart_disease_risk_predictor/outputs/models/deployment\",\n",
    "    exist_ok=True,\n",
    ")\n",
    "\n",
    "joblib.dump(\n",
    "    pipeline_best,\n",
    "    \"/workspaces/Heart_disease_risk_predictor/outputs/models/deployment/\"\n",
    "    \"best_model_pipeline.pkl\",\n",
    ")\n",
    "\n",
    "print(\"✅ Best model pipeline saved for deployment.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8067221",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusions & Next Steps\n",
    "\n",
    "**Conclusions**  \n",
    "\n",
    "- The best model pipeline is deployment-ready and includes preprocessing, prediction, and optional interpretability.  \n",
    "\n",
    "- Enhanced inference provides actionable outputs: risk bands and top feature contributions.  \n",
    "\n",
    "- Sample tests confirm correct alignment and prediction behavior.  \n",
    "\n",
    "**Next Steps**  \n",
    "\n",
    "1. Integrate pipeline into an API or web application for real-time predictions.  \n",
    "\n",
    "2. Implement monitoring, logging, and validation for incoming data.  \n",
    "\n",
    "3. Optionally, expand interpretability (SHAP values, LIME) for clinical insight.  \n",
    "\n",
    "4. Document the inference workflow for reproducibility and compliance.  \n",
    "\n",
    "5. Maintain a backup of the pipeline for versioning and rollback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
